這三步正是從「ML 研究」轉成「ML Engineer / MLOps」最關鍵的轉折點。  
把模型變成可商用的 API + Docker + 上線，是幾乎所有 ML 工作（尤其是台灣、新創、AI SaaS 公司）面試時最常被問到的實作能力。

以下是我為你量身設計的**最推薦學習路徑**（2026 年最新主流做法）：

### **推薦技術棧（強烈建議）**
- **API Framework**：**FastAPI**（遠勝 Flask，Pydantic v2 + async + 自動 Swagger）
- **伺服器**：Uvicorn + Gunicorn（production）
- **模型載入**：global + startup event（最重要！）
- **Deployment**：**Render.com**（目前最簡單、最快、最適合初學者，免費 tier 就夠用）

### **Step 10：實作 ML Model API（最重要的一步）**

**最佳實踐**：
- 模型**只載入一次**（放在 global + startup）
- 使用 Pydantic 做輸入驗證
- 回傳清晰的 Response Model
- 加入 health check endpoint

**推薦從這個簡單專案開始**（強烈建議你現在就做）：

**專案名稱**：Iris FastAPI + Pickle（之後可以換成你的 PyTorch / XGBoost 模型）

```python
# main.py
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel, Field
import pickle
import numpy as np
from typing import List

app = FastAPI(title="Iris Prediction API", version="1.0")

# Global model (最關鍵)
model = None
class_names = ["setosa", "versicolor", "virginica"]

@app.on_event("startup")
async def load_model():
    global model
    try:
        with open("iris_model.pkl", "rb") as f:
            model = pickle.load(f)
        print("Model loaded successfully!")
    except Exception as e:
        print(f"Model load failed: {e}")

class PredictionRequest(BaseModel):
    sepal_length: float = Field(..., gt=0, le=10)
    sepal_width: float = Field(..., gt=0, le=10)
    petal_length: float = Field(..., gt=0, le=10)
    petal_width: float = Field(..., gt=0, le=10)

class PredictionResponse(BaseModel):
    prediction: str
    probability: float
    probabilities: List[float]

@app.get("/health")
async def health():
    return {"status": "healthy", "model_loaded": model is not None}

@app.post("/predict", response_model=PredictionResponse)
async def predict(data: PredictionRequest):
    if model is None:
        raise HTTPException(status_code=503, detail="Model not loaded")
    
    input_data = np.array([[data.sepal_length, data.sepal_width, 
                          data.petal_length, data.petal_width]])
    
    pred_class = model.predict(input_data)[0]
    probas = model.predict_proba(input_data)[0]
    max_prob = float(max(probas))
    
    return {
        "prediction": class_names[pred_class],
        "probability": max_prob,
        "probabilities": [round(p, 4) for p in probas]
    }
```

**requirements.txt**：
```
# Web 框架與伺服器
fastapi==0.115.2
uvicorn==0.32.0

# 資料驗證與模型
pydantic==2.9.2

numpy>=1.23.0,<1.27.0
scikit-learn==1.5.2
```

**啟動**：`uvicorn main:app --reload --host 0.0.0.0 --port 8000`

### **Step 11：Docker 打包（Production 標準）**

**最佳 Dockerfile（多階段建置）**：

```dockerfile
# Dockerfile
FROM python:3.11-slim

WORKDIR /app

COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

COPY . .

EXPOSE 8000

CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]
```

建置與測試：
```bash
docker build -t iris-api:latest .
docker run -p 8000:8000 iris-api:latest
```
- 「請 Docker 根據目前資料夾的 Dockerfile，建置一個新的 Docker 映像檔（image），並幫它取名字叫 iris-api:latest」
- 「用 iris-api:latest 這個 image 啟動一個容器，並讓我可以用電腦的 8000 埠訪問容器裡的 API 服務。」

### **Step 12：上線 Deployment（推薦順序）**

**最推薦 → Render.com**（免費 + 最簡單，台灣延遲可接受）
1. 註冊 Render → New → Docker Service
2. 連 GitHub repo
3. Root Directory: `/`
4. Docker Command: `gunicorn main:app -w 2 -k uvicorn.workers.UvicornWorker --host 0.0.0.0 --port $PORT`
5. Environment Variables → `PORT=10000`
6. 部署完成 → 自動給你 HTTPS URL

**次推薦**：
- Railway.app（介面漂亮，免費額度高）
- Hugging Face Spaces（如果你想做 Gradio + API 混合）
- AWS Lightsail / EC2（進階，之後再學）

### **建議練習專案（由易到難）**
1. Iris / Titanic（scikit-learn + pickle）← **現在就做**
2. PyTorch 圖像分類（MNIST / ResNet18，用 TorchScript 或 ONNX）
3. Hugging Face Transformer（sentiment / 中文 BERT）
4. 多模型版本管理 + A/B testing

**進階必學（做完這三步後）**：
- ONNX Runtime（跨框架、加速推理）
- Batch prediction + async
- Prometheus + Grafana 監控
- Model versioning（MLflow / BentoML）
- Kubernetes + KServe（大公司才需要）

請問你目前的情況：
- 你主要用的框架是 scikit-learn、XGBoost、光 PyTorch，還是 Transformer？
- 你有沒有已經訓練好的模型想部署？
- 你希望我給你 **PyTorch 版本** 的完整範例（ResNet / ViT）嗎？

告訴我你的情況，我可以立刻給你對應的完整專案範本 + GitHub 結構建議。

繼續加油！你現在走的這條路，已經比 90% 的「只會 Jupyter」的人強太多了！  
這三步做完，你就真正具備 **Production ML Engineer** 的基本能力了。
